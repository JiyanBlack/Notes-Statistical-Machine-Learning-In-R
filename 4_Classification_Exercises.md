## Q4
#### a
On average, only 10% of the total data is used to make the prediction.
#### b
With 2 predictors, 0.1 * 0.1 = 1% of the total observations are used to make the prediction.
#### c
With 100 preditors, 0.1^98 % is used to make the prediction.
#### d
The drawback of KNN is when p is large, the prediction is less reliable.
#### e
x ^ p = 0.1, x = 0.1^(1/p)

## Q5
#### a
If the Bayes decision boundary is linear, QDA performs better on the training set. LDA is better on the test set.
#### b
If it is non-linear, QDA is better on both testing and training dataset.
#### c
As n increases, the QDA will become more accuracy than LDA. Because QDA has high variance, so is better for large dataset.
#### d
False. Because the assumed model for QDA is wrong, there is no way it could perform better than LDA.

## Q6
#### a
log(p/(1-p)) = -6 + 0.05 * X1 + 1 * X2,  p = 0.3773.
#### b
log(1) = 0 = -6 + 0.05 * X1 + 3.5, X1 = 50.

## Q7
p = 0.75186

## Q8
We should use KNN. Because KNN can gain much better performance with the increasing number of samples.
